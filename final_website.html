
<html>
	<head>
		<title>Final</title>
		<link rel="stylesheet" type="text/css" href="milestone_style.css">
	</head>

	<body onload="InitDemo();">
		<h1> Gravitational Pinball </h1>
		
		<h2> Abstract </h2>

		<p> In ancient times, our ancestors looked up to the stars and wondered what lay beyond. In modern times, we need look no farther than our computer screens. Gravity Pinball is a 3D interactactive gravity simulator WebGL that allows users to expereince and play with the cosmic forces that shaped our universe. WebGL is used to render realistic 3D models of planets and stars. Texture and bump mapping add to the detail of these simulated modies by adding fine details which are too small for the mesh. Stars are rendered similarly to planets, but produce light which can fall on and illuminate other objects. All of these objects are controlled by the forces of gravity, which is goverend by Newton's gravity equations. Each pair of objects produces a force on each other object, which causes motion. Kepler's laws of orbital bodies are emergant behavior of this system. Finally, users can interact with the program by rotating or panning the camera, or by adding new planets of any size or mass and shooting them off. </p>

		<h2> Technical Approach </h2>

		<ul>
			<li>
				<h3>WebGL</h3>
				<p>It was important to us that we make our project more or less from scratch. Our startercode was composed only of a tutorial<sup>1</sup> we followed for rendering a triangle in WebGL. One large technical hurdle therefore was getting WebGL up and running correctly. Throughout the project we made heavy reference to Mozillas WebGL documentation<sup>2</sup></p>
			</li>
			<li>
				<h3>Rendering Spheres</h3>
				<p> Once we were able to render a triangle in 3D space, our next step was to encode the rendering of a sphere, which is the shape of most of the objects we will be rendering throughout the project. We, again, elected to do this from scratch. Out method involved forming a sphere from triangles by dividing the sphere into latitudes and logitudes, much like you would a real planet. A constructor funciton takes in the number of latitudinal lines and logitudinal lines of the desired output sphere. We then iterate across two angles: directly up (towards the north pole) to 180 degrees in the other direction, and directly out along the x axis, all the way back around 360 degrees. For example, if we wish to only have 1 latitude line and 4 longitude lines (this owuld look like a diamond shape) our first angle would start at 0, then 90, then 180 and our second angle would start at 0, then 90, then 180, then 270, then 360. In general, each section of the iteration will give us a quadrilateral segment on the surface of the sphere which we will fill with two triangles. 
			</li>
			<li>
				<h3>Simulating Gravity</h3>
				<p> The bread and butter of our project involves simulating gravity. In addition to the triangles which make up a sphere, we give spheres a number of other properites including mass. This allows us to to calculate forces which will move the spheres in relation to one another. Because we have each sphere's mass, to calculate the total force we will simply interate through all of the other spheres and calculate the force of gravity between them
				</p>

				<div class="equation">
					<i>(G * M<sub>1</sub> * M<sub>2</sub>) / r<sup>2</sup></i>
				</div>

				<p>The direction of this force will of course be the unit vector pointing from the sphere of interests center, to the center of the other sphere. Once we have net force acting on a sphere, we can get its acceleration by simply dividing by it's mass. We can also get a good approximation of it's velocity by taking the difference between it's last positing and it's current position. Through these peices, we can solve for the sphere's new positiong by substituting these values into the formula: 
				</p>
				<div class="equation">
					<i>X<sub>new</sub> = X<sub>old</sub> + V*t + A*t<sup>2</sup></i>
				</div>

				<p> Where the time is simply derived from our framerate. With all of these peices we have a fairly robust gravity simulation from which we can see emergant properties such as planet orbits, and Kepler's laws of planetary motion.</p>

				<p> This method of updating position is similar to Euler's method<sup>3</sup>. This method is know for divergant behavior, so why did it work for us? including the acceleration in our update equation (instead of just using it to update the accelartion) is part of the reason. We also have the advantage of a quick update time. Because our program is running in real time on WebGL, the time between updates is very small, mitigating the issues with divergance. Finally, we are helped by not being dogmatically attached to real workd physics. Because this is Gravity <i>Pinball</i>, we wanted our planets to bounce off of each other on collisions. Normally bouncing such as this would be considered divergant behavior, but since it's exactly what we were after, we can just call it a feature. More on bouncing in a second</p>
			</li>
			<li>
				<h3>Planet Collisions</h3>

				<p> Up until this point, planets are able to clip through each other. In addition to looking strange, this has an unforntunate consequence of two planet centers coming arbitrarily close together and the force between them nearing infinity. In order to rectify this, we impliment a 'bouncing' feature. When two planets clip through one another (that is, a planet is moved such that it the distance between it's center and the center of another planet is less than the sum of their radii), instead of applying an attractive gravitation force between them, we apply a repelling force. This has the added benefit of scaling the force of bounces according to how fast planets. The faster they move, the farther inside one another they clip and the larger the repelant force added. <p>
			</li>

			<li>
				<h3>User Interaction</h3>

				<p>Because our project is essentially a game, we want to give users a breadth of options and make them easy to use. The first step of this is motion. Our camera is defined by two points and a vector. we have a camera position, a position that the camera is 'looking' at, and the up position of the camera. First we impliment camera rotation. Our camera can rotate around the 'looking at point', initially the origin. From the user's end, this involves clicking and dragging on the screen.<p>

				<p>In order to impliment this, we add event listeners to detect a click on the canvas. If there is a click, we add an event listener for mouse movement, which we will delete as soon as the click is released<sup>4</sup>. We then get the distance from the starting point to the ending point on the canvas, which we split into differance in x and difference in y. Because we know the FOV of our camera, we can convert this to degrees in the up-down direction and degrees in the left-right direction. finally, we rotate the camera around out 'looking at' point by those two degrees to get the new location. This detection is done at every mousemove, so we get smooth motion.</p>

				<p> We also added the ability to pan the camera in any direction. This is simpler than dragging. The direction from our camera to our 'looking at' point defines to forward direction, the camera up vector defines our up direction, and the cross product of these defines the left direction. We then add an event listener for arrow key presses<sup>5</sup> and the 'w' and 's' key, mapping each key to a different direction. We update both the camera position and the 'looking at' position by the same amount.

				<p> With motion implimented, we moved on to the ability to add planets. We wanted this to be intuitive for the user, so we elected to sue the mouse. A button is set to toggle whether mouse clicks in the canvas is set to rotating the camera as we have just seen, or adding a new planet. When the user is in planet adding mode, a click will create a planet in front of them. Clicking a holding will show an expanding circle overlay that indicates how fast we will shoot the planet out. The location of the click defines the angle that it will shoot out, so that you can aim. The overlay is actually an HTML element, dynamically added and edited by javascript in order to change in size. We use an ease function to convert the time the cursor is held into the power with which to shoot the planet. </p>

				<p> Finally, a series of sliders and checkboxes determine various properties of the planet that will be shot. these include the new planets mass, size, as well as if it is a star or not (more on this later). Under the hood, javascript simply reads these values from the HTML and converts them into userful measurments for mass and radius before creating the sphere.</p>
			</li>

			<li>
				<h3>Dynamic Lights</h3>

				<p>In class, we saw how to use Blinn-Phong shading with a specified light source. In these project, that was more complicated for two reasons. The first is that our lights are 'stars' which we treat like planets, except that they produce light. This means that our light sources are moving. Second, users have the ability to add stars themselves. This means that there are many light sources, and the total number is subject to change arbitrarily.<p>

				<p> In order to make a light move with a star, we need to keep track of which planets are stars. When we go to move one of these planets, we have to update the light's position as well to be in the center of the planet. Because lights are 'uniforms' in our shaders, this means updating the uniform at each frame. We also have to be sure that we update the star locations <i>before</i> any of the other planets. Otherwise different plaents will be rendered using lights from different locations dependign on if they were before or after the star update. When we make a star, we then have to add its triangles in the opposite direction to the front of our list of triangles.</p>

				<p>Having a dynamically changing number of lights is harder. Instead of doing one render where we take into account all of the lights, we have to do a render for each light individually, then sum up the result to get our final image. This way, we can have only one light uniform as input to our shaders, and change it's value at each new render. Because light is additive, we get the correct result.</p>
			</li>

			<li>
				<h3>Texture Mapping</h3>

				<p>To begin working on texture mapping, we consulted an online tutorial about mapping textures in WebGL<sup>6</sup>. While this gave us most of the building blocks we needed to construct our texture mapping, figuring out where each of the specific pieces fit together in our code was more of a struggle.  One issue we especially struggled with was that we were unable to use downloaded images from our local drive, which was not immediately clear.  However, we were able to find some textures online which we could use to map onto our objects.<p>
				
				<p>Once we had figured out how to map textures onto our objects, we had to figure out how to assign the coordinate mapping to our spheres.  Using the same general approach that we did to rendering our triangles, we measured the angle away from directly up on our sphere and the angle of rotation around the axis that goes through the sphere vertically.  With these two angles, we mapped the x-axis of our texture map to the first angle and the y-axis to the other angle.</p>
				
				<p>Finally, in the fragment shader itself, we kept the Blinn-Phong shading scheme but then multiplied it by the texture map which was created by our texture sampler.  This allowed us to project the texture onto our spheres while still retaining lighting from specific sources, creating a realistic looking simulation.</p>
			</li>

		</ul>

		<h2> Results </h2>
		<h3 class="sub"> <i> interactive gravity simulation running in real time in webGL </i></h2>

		<img src="https://images.pexels.com/photos/8892/pexels-photo.jpg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260" crossOrigin="anonymous" id="immy" style="display:none">
		<div id="canvas_div" align="center"></div>
		<div id="fire_pointer"> </div>
		<div id="fire_pointer_small"> </div>


		<canvas id="render_canvas" height="500px" width="500px">
			Your Browser Does not support WebGl
		</canvas>

		<br />

		<script src="app.js"></script>
		<script src="gl-matrix.js"></script>

		<!-- Vertex Shader for WebGL, not to be rendered-->
		<script id="vertex_shader" type="not-javascript">
			precision mediump float;

			attribute vec3 vertPosition;
			attribute vec3 vertColor;
			attribute vec2 aTexPosition;

			varying vec3 fragColor;
			varying vec3 fNormal;
			varying vec3 fPosition;
			varying vec2 vTexPosition;

			uniform mat4 world_matrix_render;
			uniform mat4 view_matrix_render;
			uniform mat4 projection_matrix_render;

			void main(){
				vTexPosition = aTexPosition;
				fNormal = vec3(0.0);
				fPosition = vec3(0.0);
				fragColor = vertColor;
				fNormal = vertPosition / length(vertPosition);
				fPosition = vec3(world_matrix_render * vec4(vertPosition, 1.0));

				gl_Position = projection_matrix_render * view_matrix_render * world_matrix_render * vec4(vertPosition, 1.0);
			}
		</script>

		<!-- Fragment Shader for WebGL, not to be rendered-->
		<script id="fragment_shader" type="not-javascript">
			precision mediump float;

			uniform vec3 lPosition;
			uniform vec3 lIntensity;
			uniform bool isStar;
			uniform sampler2D u_Sampler;
			uniform float numLights;

			varying vec3 fragColor;
			varying vec3 fNormal;
			varying vec3 fPosition;
			varying vec2 vTexPosition;

			void main(){
				gl_FragColor = vec4(fragColor, 1.0);

			    float r = length(lPosition - fPosition);
			    vec3 l = (lPosition - fPosition) / r;
			   	vec3 int_vec = vec3(0.0);
			   	vec3 ambient = vec3(0.4, 0.4, 0.4) / numLights;
			   	vec3 star_ambient = vec3(5.0, 3.0, 2.0) / numLights;

			   	if(isStar){
			   		int_vec = star_ambient;
			   	}
			   	else{
				    if(dot(fNormal,l) > 0.0){
				    	int_vec = ( (lIntensity/(r*r))*dot(fNormal, l) ) + ambient;
				    }
				    else{
				    	int_vec = ambient;
				    }
				}

			    gl_FragColor = vec4(int_vec, 1.0)*texture2D(u_Sampler, vTexPosition);
			}
		</script>
		<div id="center_div">
		<button onclick="InitDemo();" id="restart_button"> Regular Demo </button>
		<button onclick="InitDemo(true);" id="restart_button"> Stationary Demo </button>
		Firing Mode: <input type="checkbox" id="firingMode" onclick="switch_add_or_move()">
		Is Stationary: <input type="checkbox" id="isStationary">
		Is Star: <input type="checkbox" id="isStar">
		</br>
		Planet Radius<input type="range" min="1" max="200" value="30" class="slider" id="planetRadius">
		Planet Mass<input type="range" min="1" max="300" value="70" class="slider" id="planetMass">
		</br>
		Camera Movement Speed<input type="range" min="1" max="100" value="10" class="slider" id="cameraSpeed">
		</div>


		<h2> References </h2>
		<ol>
			<li> <a href="https://www.youtube.com/watch?v=kB0ZVUrI4Aw">WebGL Tutorial 01 - Setup and Triangle</a> </li>
			<li> <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGLRenderingContext/enable"> Mozilla WebGL documentation </a> </li>
			<li> <a href="https://cs184.eecs.berkeley.edu/lecture/simulation/slide_025"> CS184 Lecture Slides March 19<sup>th</sup>: Into to Simulation </a> </li>
			<li> <a href="https://stackoverflow.com/questions/15505272/javascript-while-mousedown"> StackOverflow: Javascript While MouseDown </a> </li>
			<li> <a href="https://stackoverflow.com/questions/12886286/addeventlistener-for-keydown-on-canvas"> StackOverflow: addEventListener for keydown on Canvas</a> </li>
			<li><a href="http://learnwebgl.brown37.net/10_surface_properties/texture_mapping_images.html"> Learn WebGL: Texture Mapping Using Images</a></li>

		</ol>
		
		<h2> Contributions </h2>
		<ol>Jacob Green
			<li></li>

		<div style="text-align:center;"><a href="https://www.youtube.com/watch?v=g0pZAiH-bnM&feature=youtu.be&hd=1" style="font-size:35px;"> VIDEO </a></div>
		<div style="text-align:center;"><a href="https://docs.google.com/presentation/d/1DgpgvnQyiamcUaq1dkLUnyq8NdPVK4QJvYyoELm4bi0/edit?usp=sharing" style="font-size:35px;"> SLIDES </a></div>

	</body>
	<!-- Vertex Shader for WebGL, not to be rendered-->
	<script id="vertex_shader" type="not-javascript">
		precision mediump float;

		attribute vec3 vertPosition;
		attribute vec3 vertColor;
		varying vec3 fragColor;
		uniform mat4 world_matrix_render;
		uniform mat4 view_matrix_render;
		uniform mat4 projection_matrix_render;

		void main(){
			fragColor = vertColor;
			gl_Position = projection_matrix_render * view_matrix_render * world_matrix_render * vec4(vertPosition, 1.0);
		}
	</script>

	<!-- Fragment Shader for WebGL, not to be rendered-->
	<script id="fragment_shader" type="not-javascript">
		precision mediump float;

		varying vec3 fragColor;

		void main(){
			gl_FragColor = vec4(fragColor, 1.0);
		}
	</script>
</html>